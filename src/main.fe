const STATE_FREE: u32 = 0
const STATE_USED: u32 = 1
const STATE_TOP: u32 = 2
const STATE_END: u32 = 3
const STATE_ALIGN: u32 = 4
const STATE_FLAGS: u32 = 5
const STATE_MIN_SPLIT: u32 = 6


const MASK_COMPACT: u32 = 1
const MASK_SPLIT: u32 = 2

const SIZEOF_STATE: u32 = 7 * 4

const MEM_BLOCK_SIZE: u32 = 0
const MEM_BLOCK_NEXT: u32 = 1

const SIZEOF_MEM_BLOCK: u32 = 2 * 4

struct mempool { 
  pub start: u256
  pub u8: Array<u8, 8>
	pub u32: Array<u32, 8>
	pub state: Array<u32, 24> // SIZEOF_MEM_BLOCK

  fn listStats(self, block: u256) -> (u256,u256){
    let mut count: u256 = 0
    let mut size: u256 = 0
    while(block != SIZEOF_MEM_BLOCK){ 
      count += self.blockSize(block)
      size += self.blockNext(block)

    }
    return (count,size)
  }



  fn blockSize(self,block: u256) -> u32{
    return self.u32[block>>2 + MEM_BLOCK_SIZE]
  }
   fn blockNext(self,block: u256) -> u32{
    return self.u32[(block>>2) + MEM_BLOCK_NEXT]
  }

  fn malloc(mut self, bytes: u32) -> u256{
		if (bytes <= 0) {
			return 0;
		}
		let paddedSize: u32 = bytes + SIZEOF_MEM_BLOCK;
		let end: u32 = self.state[STATE_END]
		let mut top: u32 = self.state[STATE_TOP]
		let mut block: u32 = self.state[STATE_FREE]
		let mut prev: u32 = 0;
		while (u256(block) < SIZEOF_MEM_BLOCK) {
			let blockSize: u32 = self.blockSize(block)
			let isTop:bool = u256(block) + blockSize >= top;
			if  isTop or (blockSize >= SIZEOF_MEM_BLOCK) { //check for padded
				return self.mallocTop(
					block,
					prev,
					blockSize,
					paddedSize,
					isTop
				);
			}
			prev = block;
			self.state[STATE_FREE] = self.blockNext(block)
		}
		block = top;
		top = u32(u256(block) + SIZEOF_MEM_BLOCK)
		if (top <= end) {
			self.initBlock(block, size: paddedSize, next: self.state[STATE_USED]);
			self.state[STATE_USED] = block;
			self.state[STATE_TOP] = top;
			return mempool::blockDataAddress(blockAddress: block);
		}
		return 0;
	}

	fn mallocTop(mut self,block: u32,prev: u32,blockSize: u32,paddedSize: u32,isTop: bool) -> u256 {
		if (isTop and (block) + paddedSize > self.state[STATE_END]){ return 0 }
		if (prev > 0) {
			self.unlinkBlock(prev, block);
		} else {
			self.state[STATE_FREE] = self.blockNext(block);
		}
		self.setBlockNext(block, next: self.state[STATE_USED]);
		self.state[STATE_USED] = block;
		if (isTop) {
			self.state[STATE_TOP] = block + self.setBlockSize(block, size: paddedSize);
		} else if self.state[STATE_FLAGS] == 3{ //check line 338 in original code
			let excess: u32 = blockSize - paddedSize;
			if excess >= 16 { // configurable in options in TA
				self.splitBlock(block, blockSize: paddedSize, excess)
			} 
		}
		return mempool::blockDataAddress(blockAddress: block);
	}


	fn blockDataAddress(blockAddress: u256) -> u256 { 
		if blockAddress > 0 {
			return blockAddress + SIZEOF_MEM_BLOCK
		}
		else { 
			return 0
		}
	}
	fn unlinkBlock(mut self, prev: u256, block: u256) {
		self.setBlockNext(block: prev, next: self.blockNext(block));
	}

	fn setBlockNext(mut self, block: u256, next: u32) {
		self.u32[(block >> 2) + MEM_BLOCK_NEXT] = next;
	}

	fn setBlockSize(mut self, block: u256, size: u32) -> u32{
		self.u32[(block >> 2) + MEM_BLOCK_SIZE] = size;
		return size;
	}


	fn initBlock(mut self, block: u32, size: u32, next: u32) -> u32 {
		let ddd: u32 = block >> 2; //there is no unsigned shift right (no need ig) ?? idx seems to be a reserved word ?? 
		self.u32[ddd + MEM_BLOCK_SIZE] = size;
		self.u32[ddd + MEM_BLOCK_NEXT] = next;
		return block;
	}

	fn splitBlock(mut self, block: u32, blockSize: u32, excess: u32) {
		self.insert(
			block: self.initBlock(
				block: block + self.setBlockSize(block, size: blockSize),
				size: excess,
				next: 0
			)
		);
		// this.doCompact && this.compact(); NO COMPACTING FOR NOW 
	}

	fn insert(mut self, block: u32) {
		let mut ptr: u32 = self.state[STATE_FREE];
		let mut prev: u32 = 0;
		while (ptr > 0) {
			if (block <= ptr){
				break;
			} 
			prev = ptr;
			ptr = self.blockNext(block: ptr);
		}
		if (prev > 0) {
			self.setBlockNext(block: prev, next: block);
		} else {
			self.state[STATE_FREE] = block;
		}
		self.setBlockNext(block, next: ptr);
	}

	pub fn realloc(mut self, ptr: u32, bytes: u32) -> u256 {
		if (bytes <= 0) {
			return 0;
		}
		let oldAddr: u32 = mempool::blockSelfAddress(dataAddress: ptr);
		let mut newAddr: u32 = 0;
		let mut block: u32 = self.state[STATE_USED];
		let mut blockEnd: u32 = 0;
		let mut pair1: (u32,u32) = (0,0);
		while (block > 0) {
			if (block == oldAddr) {
				pair1 = self.reallocBlock(block, bytes);
				newAddr = pair1.item0
				blockEnd = pair1.item1
				break;
			}
			block = self.blockNext(block);
		}
		// copy old block contents to new addr
		if (newAddr > 0 and newAddr != oldAddr) {
			// self.u8.copyWithin(    ---copyWithin copies data from index arg0 to index arg1 and ending at arg2
			// 	blockDataAddress(newAddr),
			// 	blockDataAddress(oldAddr),
			// 	blockEnd
			// );
		}
		return mempool::blockDataAddress(blockAddress: newAddr);
	}

	fn reallocBlock(mut self, block: u32, bytes: u32)  -> (u32,u32) {
		let blockSize: u32 = self.u32[(block >> 2) + MEM_BLOCK_SIZE];
		let blockEnd: u32 = block + blockSize;
		let isTop: bool = blockEnd >= self.state[STATE_TOP];
		self.state[STATE_ALIGN] = bytes + SIZEOF_MEM_BLOCK
		let paddedSize: u32 = self.state[STATE_ALIGN]
		// shrink & possibly split existing block
		if (paddedSize <= blockSize) {
			if (false) { //self do split
				let excess: u32 = blockSize - paddedSize;
				if (excess >= self.state[STATE_MIN_SPLIT]) {
					self.splitBlock(block, blockSize: paddedSize, excess);
				} else if (isTop) {
					self.state[STATE_TOP] = block + paddedSize;
				}
			} else if (isTop) {
				self.state[STATE_TOP] = block + paddedSize;
			}
			return (block, blockEnd);
		}
		// try to enlarge block if current top
		if (isTop and block + paddedSize < self.state[STATE_END]) {
			self.state[STATE_TOP] = block + self.setBlockSize(block, size: paddedSize);
			return (block, blockEnd);
		}
		// fallback to free & malloc
		//this.free(block);
		return (mempool::blockSelfAddress(dataAddress: u32(self.malloc(bytes))), blockEnd)
	}
	fn blockSelfAddress(dataAddress: u32) -> u32 { 
			if dataAddress > 0 {
				return dataAddress - SIZEOF_MEM_BLOCK
			}
			else {
				return 0
			}
		}
}


